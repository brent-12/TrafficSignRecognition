{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tfrms\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = \"./train\"\n",
    "labelFile = \"SignCSV.csv\"\n",
    "epochValue = 30\n",
    "imageDimension = (32,32,3)\n",
    "testRatio = 0.2\n",
    "validationRatio = 0.2\n",
    "batch_size_val = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # Read the CSV file to get the labels\n",
    "    df = pd.read_csv(labelFile)\n",
    "    \n",
    "    # Lists to store images and their labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the image filename and label from the CSV\n",
    "        image_file = row['filename']  # Change this column name if needed\n",
    "        label = row['label']  # Change this column name if needed\n",
    "        \n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(picture, image_file)\n",
    "        \n",
    "        try:\n",
    "            # Open and resize the image, then convert it to an array\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            img = img.resize(32,32)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append the image and label to the respective lists\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any transformations (e.g., normalization, resizing if not already done)\n",
    "dTransforms = tfrms.Compose([\n",
    "    tfrms.ToPILImage(),\n",
    "    tfrms.ColorJitter(hue=0.4),\n",
    "    tfrms.RandomHorizontalFlip(1),\n",
    "    tfrms.RandomVerticalFlip(1),\n",
    "    tfrms.RandomAffine(degrees = 15, shear=2),\n",
    "    tfrms.CenterCrop(32),\n",
    "    tfrms.Grayscale(num_output_channels=3),\n",
    "    tfrms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=2,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256,out_channels=320,kernel_size=3,padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=320,out_channels=256,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.classifcation = nn.Sequential(\n",
    "            nn.Dropout(0,5),\n",
    "            nn.Linear(16*256, 600),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0,5),\n",
    "            nn.Linear(in_features=600, out_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = self.conv(x)\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        Y = self.classifcation(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, epochs=10, batch_size=32, learning_rate=0.001, device=None):\n",
    "\n",
    "    # Use GPU if available, otherwise fall back to CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)  # Move the model to the chosen device\n",
    "\n",
    "    # Set up DataLoader for batching and shuffling\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Set up the optimizer (Adam) and loss function (CrossEntropyLoss)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Iterate over the DataLoader to get batches of images and labels\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            # Move images and labels to the same device as the model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: Get model outputs\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: Compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss for reporting\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Track accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Print the epoch results\n",
    "        avg_loss = running_loss / len(data_loader)\n",
    "        accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class to load images and labels\n",
    "class NewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_folder, labels_csv, image_size=(32, 32), transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.labels_df.iloc[idx, 0]  # assuming first column is image filename\n",
    "        label = self.labels_df.iloc[idx, -1]  # assuming last column is the label\n",
    "        \n",
    "        # Construct the full image path\n",
    "        image_path = os.path.join(self.images_folder, str(image_name))  # Ensure correct path\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image not found: {image_path}\")\n",
    "            # Return a default image (e.g., a blank image) or skip the sample\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Open and process the image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.resize(self.image_size)\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return None  # In case of error, return None\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def encode_labels(dataset):\n",
    "    if dataset.labels_df['label'].dtype == object:\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataset.labels_df['encoded_label'] = label_encoder.fit_transform(dataset.labels_df['label'])\n",
    "    else:\n",
    "        label_encoder = None\n",
    "    return dataset, label_encoder\n",
    "\n",
    "# Example to load the data and train\n",
    "def load_and_train(model, images_folder, labels_csv, batch_size, epochs, learning_rate, device):\n",
    "    # Load dataset\n",
    "    transform = tfrms.Compose([\n",
    "        tfrms.ToTensor(),\n",
    "        tfrms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Example normalization\n",
    "    ])\n",
    "    \n",
    "    dataset = NewDataset(images_folder, labels_csv, image_size=(32, 32), transform=transform)\n",
    "    \n",
    "    # Initialize DataLoader\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # Optimizer and loss function\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Set model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Start training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Iterate over the DataLoader\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            # Skip None images and labels\n",
    "            if images is None or labels is None:\n",
    "                continue\n",
    "\n",
    "            # Move data to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track performance\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (correct_predictions / total_samples) * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Path to dataset (replace with actual paths)\n",
    "images_folder = \"./train\"\n",
    "labels_csv = \"SignCSV.csv\"\n",
    "\n",
    "# Initialize the model\n",
    "model = DCNN()\n",
    "\n",
    "# Set the device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model\n",
    "trained_model = load_and_train(model, images_folder, labels_csv, batch_size=32, epochs=10, learning_rate=0.001, device=device)\n",
    "\n",
    "# The trained model is now ready to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
